{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--EwEaIzx9Dp",
    "outputId": "8ae00482-5346-488e-fa31-6b0af56a2c79"
   },
   "outputs": [],
   "source": [
    "!pip3 install pandas numpy datasets huggingface_hub --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "BASE_PATH = \"/home/sun/Downloads/tg_challenge/\"\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9Ison7ZmDGT"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Dy5Yw86mDLj"
   },
   "outputs": [],
   "source": [
    "PATH_TO_JSON_FILE = os.path.join(BASE_PATH, 'language_identification_dataset_100_with_messages_and_regexps.json')\n",
    "\n",
    "with open(PATH_TO_JSON_FILE, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C0y6gEIOqueg"
   },
   "outputs": [],
   "source": [
    "new_data = dict()\n",
    "for key in data:\n",
    "    if len(data[key]) == 1:\n",
    "        new_data[key] = [data[key][0]]\n",
    "    else:\n",
    "        new_data[key] = [data[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMICXnd2uB7o",
    "outputId": "134f0245-e933-4582-ab6d-9c745694c5d3"
   },
   "outputs": [],
   "source": [
    "len(new_data['TGLANG_LANGUAGE_BASIC'][0][1])\n",
    "# new_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JADulAZFqutG"
   },
   "outputs": [],
   "source": [
    "# data_for_df = [{\"class\": key, \"text\": value[0][i]} for key, value in new_data.items() for i in range(len(value[0]))]\n",
    "data_for_df = []\n",
    "\n",
    "for key, value in new_data.items():\n",
    "    for i in range(len(value[0])):\n",
    "        if key == 'TGLANG_LANGUAGE_BASIC':\n",
    "            for j in range(len(value[0][i])):\n",
    "                data_for_df.append({'class': key, 'text': value[0][i][j]})\n",
    "        else:\n",
    "            data_for_df.append({'class': key, 'text': value[0][i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxpZpRQJqu0j"
   },
   "outputs": [],
   "source": [
    "data_for_modeling = pd.DataFrame(data_for_df).sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0Lg745Rxz2S"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHVKpPyesiMP"
   },
   "outputs": [],
   "source": [
    "modeling_data_file = os.path.join(BASE_PATH, \"data_for_modeling.json\")\n",
    "data_for_modeling.to_json(modeling_data_file)\n",
    "data = pd.read_json(modeling_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m8Wg04lhgzNx",
    "outputId": "a3b87d46-55a9-4948-cfdc-860f7eddea12"
   },
   "outputs": [],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJbFpq5b4z1N"
   },
   "outputs": [],
   "source": [
    "IMBALANCED_CLASSES = [\n",
    "    \"TGLANG_LANGUAGE_REGEX\",\n",
    "    \"TGLANG_LANGUAGE_OTHER\",\n",
    "]\n",
    "\n",
    "balanced_based = data[~data['class'].isin(IMBALANCED_CLASSES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YG4pTIFq5VFI"
   },
   "outputs": [],
   "source": [
    "balanced_dfs = [data[data['class'] == CLASS].sample(100, random_state=42) for CLASS in IMBALANCED_CLASSES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klV7rxpr5hTr"
   },
   "outputs": [],
   "source": [
    "balanced_data = pd.concat([balanced_based, *balanced_dfs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixEKKMcn55DO"
   },
   "outputs": [],
   "source": [
    "balanced_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSXGJuKgwJfR"
   },
   "outputs": [],
   "source": [
    "# data[data['class'] == 'TGLANG_LANGUAGE_CPLUSPLUS'].text.str.contains(\"//\").astype(int)\n",
    "\n",
    "# all(isinstance(value, str) for value in data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aq3VfrjsmDPE"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56X6EN1XmEAN"
   },
   "outputs": [],
   "source": [
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, PredefinedSplit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting into folds\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "K_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# evaluation utils\n",
    "def generate_folding(k_folds: int, df: pd.DataFrame) -> List[int]:\n",
    "\n",
    "    len_folding = df.shape[0] // k_folds\n",
    "    all_folding = []\n",
    "    for i in range(k_folds):\n",
    "\n",
    "        if i != k_folds - 1:\n",
    "            all_folding += [i + 1 for _ in range(len_folding)]\n",
    "        else:\n",
    "            len_folds_computed = df.shape[0] - len(all_folding)\n",
    "            all_folding += [i + 1 for _ in range(len_folds_computed)]\n",
    "    return all_folding\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_fold_for_iteration(fold_indices, test_fold_num):\n",
    "    return [0 if f == test_fold_num else -1 for f in fold_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Refactor\n",
    "def train_multiple_folds(n_folds: int, df: pd.DataFrame, vectorizer: object) -> List[float]:\n",
    "\n",
    "    X = vectorizer.fit_transform(df['text'])\n",
    "    y = df['class']\n",
    "\n",
    "    test_folding = generate_folding(k_folds=n_folds, df=df)\n",
    "\n",
    "    clf = MultinomialNB()\n",
    "    all_scores = []\n",
    "\n",
    "    for fold_num in tqdm(range(n_folds)):  # As we have 4 folds\n",
    "        current_test_fold = get_test_fold_for_iteration(test_folding, fold_num)\n",
    "        ps = PredefinedSplit(current_test_fold)\n",
    "        scores = cross_val_score(clf, X, y, cv=ps, scoring='f1_macro')\n",
    "        all_scores.extend(scores)\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(data['text'])\n",
    "y = data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, len(data), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = MultinomialNB()\n",
    "# usual traning would be here\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = clf.fit(train_X, train_y)\n",
    "mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.feature_log_prob_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.score(val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skl2onnx import to_onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType, Int64TensorType, DoubleTensorType\n",
    "to_onnx?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X.shape[1]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_types = [('float_input', FloatTensorType([None, cols]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_clf = to_onnx(clf, initial_types=initial_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path = os.path.join(BASE_PATH, \"mnb-1.onnx\")\n",
    "with open(onnx_path, \"wb\") as f:\n",
    "    f.write(onnx_clf.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah mnb-1.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = clf.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(onnx_path, providers=[\"CPUExecutionProvider\"])\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_val_X = val_X[:1000].toarray().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_val_X.shape, t_val_X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_onx = sess.run([label_name], {input_name: t_val_X})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_onx[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equals = pred_onx[:1000] == pred_y[:1000]\n",
    "sum(equals) == 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e-5S9FxsuXg",
    "outputId": "9b540145-bf01-4b92-f573-71054f79e050"
   },
   "outputs": [],
   "source": [
    "# test_folding = generate_folding(k_folds=K_FOLDS, df=data)\n",
    "\n",
    "# # k-fold cross validation\n",
    "# all_scores = []\n",
    "\n",
    "# for fold_num in tqdm(range(K_FOLDS)):\n",
    "#     current_test_fold = get_test_fold_for_iteration(test_folding, fold_num + 1)\n",
    "#     ps = PredefinedSplit(current_test_fold)\n",
    "#     # breakpoint()\n",
    "#     # print(pd.Series(current_test_fold).value_counts())\n",
    "#     scores = cross_val_score(clf, X, y, cv=ps)\n",
    "#     all_scores.extend(scores)\n",
    "\n",
    "# print(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xSlN1GzZr9S",
    "outputId": "15ac5b3d-bd7e-4326-ef9b-ca3d4c3661bc"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn onnx onnxruntime skl2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_EFHB2yZBmX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftyf8gL7Y21W"
   },
   "source": [
    "### TODO: per-class evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T4FTyEW80Pjw",
    "outputId": "92e567dd-4b11-4708-8ff3-d6f768cad5c4"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "# X = vectorizer.fit_transform(balanced_data['text'])\n",
    "# y = balanced_data['class']\n",
    "\n",
    "# train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=42)\n",
    "# clf = MultinomialNB()\n",
    "# clf.fit(train_X, train_y)\n",
    "\n",
    "# pred_y = clf.predict(val_X)\n",
    "\n",
    "# # precision_per_class = precision_score(val_y, pred_y, average=None)\n",
    "# # recall_per_class = recall_score(val_y, pred_y, average=None)\n",
    "# # f1_per_class = f1_score(val_y, pred_y, average=None)\n",
    "\n",
    "# report = classification_report(val_y, pred_y, output_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1eBJFFyT2gE3"
   },
   "outputs": [],
   "source": [
    "# report_df = pd.DataFrame(report).T.reset_index().rename(columns={'index': 'class'})\n",
    "# report_df\n",
    "\n",
    "# report_df[report_df['class'] == '']\n",
    "# data['class'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aP1G9QI03WOW"
   },
   "outputs": [],
   "source": [
    "# report_df[report_df['class'] == 'TGLANG_LANGUAGE_REGEX'].reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ems4kAhBtZM8"
   },
   "outputs": [],
   "source": [
    "# for i, row in data.iterrows():\n",
    "#     if type(row['text']) == list:\n",
    "#         print(i)\n",
    "\n",
    "# data.loc[900, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EffzT4B1swno"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y92lRqlJtOCo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ftyf8gL7Y21W"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
